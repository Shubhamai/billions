{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llama import Transformer, LlamaModelConfig\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "config = LlamaModelConfig(dim=1024, n_layers=4, n_heads=8, device=torch.device('mps'), vocab_size=enc.n_vocab)\n",
    "model = Transformer(config).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 10]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "with open(\"data.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "data = data[:1000]\n",
    "\n",
    "tokens = enc.encode(data)\n",
    "batch, seq_length = 10, 10\n",
    "buf = torch.tensor(tokens[:batch*seq_length + 1])\n",
    "x = buf[:-1].view(batch, seq_length).to(config.device)\n",
    "y = buf[1:].view(batch, seq_length).to(config.device)\n",
    "\n",
    "(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 10.775420188903809\n",
      "step 1, loss 6.702307224273682\n",
      "step 2, loss 4.30055046081543\n",
      "step 3, loss 2.657411575317383\n",
      "step 4, loss 1.5805739164352417\n",
      "step 5, loss 0.8441224098205566\n",
      "step 6, loss 0.5864062309265137\n",
      "step 7, loss 0.39129066467285156\n",
      "step 8, loss 0.30061760544776917\n",
      "step 9, loss 0.20988021790981293\n",
      "step 10, loss 0.1405230462551117\n",
      "step 11, loss 0.10673884302377701\n",
      "step 12, loss 0.07578655332326889\n",
      "step 13, loss 0.06813423335552216\n",
      "step 14, loss 0.040609169751405716\n",
      "step 15, loss 0.041371963918209076\n",
      "step 16, loss 0.01969420351088047\n",
      "step 17, loss 0.02046218328177929\n",
      "step 18, loss 0.015620528720319271\n",
      "step 19, loss 0.008271520957350731\n",
      "step 20, loss 0.0068757785484194756\n",
      "step 21, loss 0.0069276620633900166\n",
      "step 22, loss 0.004749912768602371\n",
      "step 23, loss 0.0037273720372468233\n",
      "step 24, loss 0.003299026982858777\n",
      "step 25, loss 0.0030108648352324963\n",
      "step 26, loss 0.0027866375166922808\n",
      "step 27, loss 0.002602060092613101\n",
      "step 28, loss 0.0024380988907068968\n",
      "step 29, loss 0.0022794038522988558\n",
      "step 30, loss 0.0021199877373874187\n",
      "step 31, loss 0.0019634703639894724\n",
      "step 32, loss 0.0018170003313571215\n",
      "step 33, loss 0.001685017254203558\n",
      "step 34, loss 0.0015685021644458175\n",
      "step 35, loss 0.00146625773049891\n",
      "step 36, loss 0.0013764421455562115\n",
      "step 37, loss 0.0012971971882507205\n",
      "step 38, loss 0.0012268904829397798\n",
      "step 39, loss 0.0011642585741356015\n",
      "step 40, loss 0.0011081633856520057\n",
      "step 41, loss 0.0010578035144135356\n",
      "step 42, loss 0.0010123361134901643\n",
      "step 43, loss 0.0009712260798551142\n",
      "step 44, loss 0.0009339154348708689\n",
      "step 45, loss 0.0008999351412057877\n",
      "step 46, loss 0.0008688882226124406\n",
      "step 47, loss 0.0008404598920606077\n",
      "step 48, loss 0.0008143520099110901\n",
      "step 49, loss 0.0007903423975221813\n"
     ]
    }
   ],
   "source": [
    "# output, loss = model(x, 0, y)\n",
    "# loss\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "for i in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output, loss = model(x, 0, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"step {i}, loss {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sampling loop for a single batch exmple\n",
    "def sample(model, x, n=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            output, _ = model(x[:, :i+1], 0)\n",
    "            next_token = torch.argmax(output[:, -1, :], dim=-1)\n",
    "            x = torch.cat([x, next_token.view(10, 1)], dim=1)\n",
    "    return x\n",
    "\n",
    "output = sample(model, x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, Citizen:\\nBefore we proceed any further, hear'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0, :].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
